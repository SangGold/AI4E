{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rh50rhxLstde"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
        "    def eraser(input_img):\n",
        "        img_h, img_w, img_c = input_img.shape\n",
        "        p_1 = np.random.rand()\n",
        "\n",
        "        if p_1 > p:\n",
        "            return input_img\n",
        "\n",
        "        while True:\n",
        "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
        "            r = np.random.uniform(r_1, r_2)\n",
        "            w = int(np.sqrt(s / r))\n",
        "            h = int(np.sqrt(s * r))\n",
        "            left = np.random.randint(0, img_w)\n",
        "            top = np.random.randint(0, img_h)\n",
        "\n",
        "            if left + w <= img_w and top + h <= img_h:\n",
        "                break\n",
        "\n",
        "        if pixel_level:\n",
        "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
        "        else:\n",
        "            c = np.random.uniform(v_l, v_h)\n",
        "\n",
        "        input_img[top:top + h, left:left + w, :] = c\n",
        "\n",
        "        return input_img\n",
        "\n",
        "    return eraser"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYtX-h24s572"
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, UpSampling2D, Flatten, BatchNormalization, Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "import tensorflow as tf\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from skimage.transform import resize\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAXAoNZ6s7nL"
      },
      "source": [
        "num_classes = 100\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "nrJWIJjwDifo",
        "outputId": "e0928af7-8519-4923-f406-0fc37c747e98"
      },
      "source": [
        "plt.imshow(x_train[1])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f19c2687fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLS_T7gEDQiZ"
      },
      "source": [
        "#Pre-process the data\n",
        "x_train = preprocess_input(x_train)\n",
        "x_test = preprocess_input(x_test)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "XigXlwr0DXQZ",
        "outputId": "b47fd5c8-f10d-423b-8305-d209ab4c5682"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_train[1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f19c274e750>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbQFdSr6s_Ot"
      },
      "source": [
        "# one-hot encoding\n",
        "y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = np_utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5D0L_oCtBIe",
        "outputId": "331ee88c-85e3-4ddd-c16e-abb1291c5ad0"
      },
      "source": [
        "x_val = x_train[40000:50000, ]\n",
        "x_train = x_train[:40000, ]\n",
        "y_val = y_train[40000:50000]\n",
        "y_train = y_train[:40000]\n",
        "print(x_train.shape, y_train.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40000, 32, 32, 3) (40000, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "-qBpGyMBCnht",
        "outputId": "70f90b6f-77a2-4986-e5cb-a917697e0704"
      },
      "source": [
        "size = (224, 224)\n",
        "\n",
        "x_train = x_train.map(lambda x, y: (tf.image.resize(x, size), y))\n",
        "x_val = x_val.map(lambda x, y: (tf.image.resize(x, size), y))\n",
        "x_test = x_test.map(lambda x, y: (tf.image.resize(x, size), y))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-7f648c0ec0aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mx_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'map'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j09KmidetCm2"
      },
      "source": [
        "data_gen = ImageDataGenerator(preprocessing_function=get_random_eraser(v_l=0, v_h=1, pixel_level=True))\n",
        "data_gen.fit(x_train)\n",
        "val_gen = ImageDataGenerator(preprocessing_function=get_random_eraser(v_l=0, v_h=1, pixel_level=True))\n",
        "val_gen.fit(x_val)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmWRlVSCtHuQ"
      },
      "source": [
        "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "for layer in resnet_model.layers:\n",
        "    if isinstance(layer, BatchNormalization):\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "model = Sequential()\n",
        "model.add(UpSampling2D())\n",
        "model.add(UpSampling2D())\n",
        "model.add(UpSampling2D())\n",
        "model.add(resnet_model)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXAH2kvfFaS2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK78ljSXtMn6"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "Y7_jAW6qtQ0S",
        "outputId": "befdec65-ccb3-46cf-b47a-25902673e716"
      },
      "source": [
        "t=time.time()\n",
        "bt_size = 64\n",
        "Epoch = 6\n",
        "historytemp = model.fit_generator(data_gen.flow(x_train, y_train,\n",
        "                                  batch_size=bt_size),\n",
        "                                  steps_per_epoch=x_train.shape[0] // bt_size,\n",
        "                                  epochs=Epoch,\n",
        "                                  validation_data=(val_gen.flow(x_val, y_val, batch_size=bt_size)), validation_steps=x_val.shape[0]//bt_size)\n",
        "print('Training time: %s' % (time.time() - t))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "  1/625 [..............................] - ETA: 8:59:54 - loss: 5.2925 - accuracy: 0.0156"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-c0570bf14e12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                                   \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbt_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEpoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                   validation_data=(val_gen.flow(x_val, y_val, batch_size=bt_size)), validation_steps=x_val.shape[0]//bt_size)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training time: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1987\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1988\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1989\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1991\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVPuerbwy3kb"
      },
      "source": [
        "# unfreeze weights\n",
        "for layer in resnet_model.layers:\n",
        "    layer.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8awu7kly1yq"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKONUBo5yvlR"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "es = EarlyStopping(monitor = 'val_loss', mode = 'min',\n",
        "                   patience = 10, restore_best_weights = True, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRCAD-BYyzkL",
        "outputId": "e4e678ee-b997-41d8-ff81-54564af5bdd2"
      },
      "source": [
        "hist = model.fit_generator(data_gen.flow(x_train, y_train,\n",
        "                                  batch_size=bt_size),\n",
        "                                  steps_per_epoch=x_train.shape[0] // bt_size,\n",
        "                                  epochs=30, verbose=1, callbacks=[es],\n",
        "                                  validation_data=(val_gen.flow(x_val, y_val, batch_size=bt_size)),\n",
        "                           validation_steps=x_val.shape[0]//bt_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "469/625 [=====================>........] - ETA: 4:02 - loss: 3.3619 - accuracy: 0.2630"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNjZtMIbyZ02"
      },
      "source": [
        "model.save_weight('best_w.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruuS1Payy8Jv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}