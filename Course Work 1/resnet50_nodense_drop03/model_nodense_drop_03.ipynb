{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sang.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYtX-h24s572"
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, UpSampling2D, Flatten, BatchNormalization, Dense, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.datasets import cifar100\n",
        "import tensorflow as tf\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from skimage.transform import resize\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAXAoNZ6s7nL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b6e3ef7-1b98-4b30-f021-325615369068"
      },
      "source": [
        "num_classes = 100\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 11s 0us/step\n",
            "169017344/169001437 [==============================] - 11s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5D0L_oCtBIe",
        "outputId": "a0c17eff-aa9d-453e-f569-d4a3cb7fc0db"
      },
      "source": [
        "x_val = x_train[40000:50000, ]\n",
        "x_train = x_train[:40000, ]\n",
        "y_val = y_train[40000:50000]\n",
        "y_train = y_train[:40000]\n",
        "print(x_train.shape, y_train.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40000, 32, 32, 3) (40000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FabH3TVyd_S-"
      },
      "source": [
        "import cv2\n",
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    'Generates data for keras'\n",
        "    def __init__(self, images , labels = None,  batch_size = 64,\n",
        "                 dim = (224, 224), n_classes = 100,\n",
        "                 shuffle = True):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.dim = dim\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        \n",
        "        self.indexes = np.arange(self.images.shape[0]) # (0,1,2,3,...,40000)\n",
        "\n",
        "        self.on_epoch_end()\n",
        "        \n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        \n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes) \n",
        "            \n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return self.images.shape[0] // self.batch_size \n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        'Generate batch of data in position index'\n",
        "        # index * batch_size : (index +1) *batch_size\n",
        "\n",
        "        batch_indexes = self.indexes[ index*self.batch_size:(index+1)*self.batch_size]\n",
        "        \n",
        "        images =[]\n",
        "        labels =[] \n",
        "\n",
        "        for i in batch_indexes:\n",
        "\n",
        "          img_i = self.images[i] \n",
        "          img_i = cv2.resize(img_i , self.dim )\n",
        "          img_i = (img_i) / 127. - 1 \n",
        "\n",
        "          # augm.... \n",
        "          images.append(img_i)\n",
        "\n",
        "          label_i = self.labels[i]\n",
        "          labels.append(label_i)\n",
        "      \n",
        "        images = np.stack(images) # batch_size, 224,224,3\n",
        "        labels = np_utils.to_categorical(labels, self.n_classes)\n",
        "\n",
        "        return images, labels "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmWRlVSCtHuQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47f2e84b-27f0-4aea-ad5b-1268125bbfd0"
      },
      "source": [
        "resnet_model = ResNet50(weights='imagenet', include_top=False,\n",
        "                        input_shape=(224,224,3))\n",
        "avg = GlobalAveragePooling2D()(resnet_model.output)\n",
        "\n",
        "# den1 = Dense(256, activation=None)(avg)\n",
        "# bn = BatchNormalization()(den1)\n",
        "# relu = tf.keras.layers.Activation('relu')(bn)\n",
        "\n",
        "drop1 = Dropout(0.3)(avg)\n",
        "den2 = Dense(num_classes, activation='softmax')(drop1)\n",
        "\n",
        "model = tf.keras.Model(inputs = resnet_model.inputs, outputs =[den2])\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n",
            "94781440/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXAH2kvfFaS2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1265454-0df0-40c1-91b9-1c0cbdc89a13"
      },
      "source": [
        "for layer in resnet_model.layers:\n",
        "  if isinstance(layer, BatchNormalization):\n",
        "    layer.trainable = True\n",
        "  else:\n",
        "    layer.trainable = False\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 2048)         0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 2048)         0           global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 100)          204900      dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,792,612\n",
            "Trainable params: 258,020\n",
            "Non-trainable params: 23,534,592\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK78ljSXtMn6"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "data_gen = DataGenerator(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size = 64,\n",
        "    dim = (224, 224), n_classes = 100,\n",
        "    shuffle = True\n",
        ")\n",
        "val_gen  = DataGenerator(\n",
        "    x_val,\n",
        "    y_val,\n",
        "    batch_size = 64,\n",
        "    dim = (224, 224), n_classes = 100,\n",
        "    shuffle = False\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVyLsp8CLFUY"
      },
      "source": [
        "Freeze pre-train and warm up top layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7_jAW6qtQ0S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0243f8ec-83b4-4edf-a119-c1cdcc303bc7"
      },
      "source": [
        "t=time.time()\n",
        "bt_size = 64 \n",
        "Epoch = 5\n",
        "historytemp = model.fit(data_gen,\n",
        "                        validation_data=val_gen,\n",
        "                        epochs=Epoch)\n",
        "print('Training time: %s' % (time.time() - t))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "625/625 [==============================] - 705s 1s/step - loss: 1.9507 - accuracy: 0.4897 - val_loss: 4.7803 - val_accuracy: 0.1278\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 667s 1s/step - loss: 1.0077 - accuracy: 0.7042 - val_loss: 1.0163 - val_accuracy: 0.7093\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 670s 1s/step - loss: 0.7903 - accuracy: 0.7612 - val_loss: 0.9129 - val_accuracy: 0.7373\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 672s 1s/step - loss: 0.6606 - accuracy: 0.7961 - val_loss: 0.8888 - val_accuracy: 0.7468\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 673s 1s/step - loss: 0.5754 - accuracy: 0.8169 - val_loss: 0.8837 - val_accuracy: 0.7514\n",
            "Training time: 3386.941650390625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBCX8XURgZ81"
      },
      "source": [
        "test_gen = DataGenerator(\n",
        "    x_test,\n",
        "    y_test,\n",
        "    batch_size = 64,\n",
        "    dim = (224, 224), n_classes = 100,\n",
        "    shuffle = False\n",
        ")\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaM-I136G_Fe",
        "outputId": "f46ce3c3-083a-4b34-b962-7fe1b8905a03"
      },
      "source": [
        "model.evaluate(test_gen)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "156/156 [==============================] - 66s 425ms/step - loss: 0.8507 - accuracy: 0.7555\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8506616353988647, 0.7555088400840759]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFyikh0nMrxD"
      },
      "source": [
        "Unfreeze pre-train model, update entire model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVPuerbwy3kb"
      },
      "source": [
        "# unfreeze weights\n",
        "for layer in resnet_model.layers:\n",
        "    layer.trainable = True"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8awu7kly1yq"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKONUBo5yvlR"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "es = EarlyStopping(monitor = 'val_loss', mode = 'min',\n",
        "                   patience = 8, restore_best_weights = True, verbose = 1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRCAD-BYyzkL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d0a2b87-9abc-4578-9bdd-38cb56e39c61"
      },
      "source": [
        "hist = model.fit(data_gen,\n",
        "                        validation_data=val_gen,\n",
        "                  epochs=25,\n",
        "                  callbacks=[es],\n",
        "                  verbose=1\n",
        "                  )\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "625/625 [==============================] - 893s 1s/step - loss: 0.3555 - accuracy: 0.8892 - val_loss: 0.8391 - val_accuracy: 0.7624\n",
            "Epoch 2/25\n",
            "625/625 [==============================] - 890s 1s/step - loss: 0.3265 - accuracy: 0.8981 - val_loss: 0.8018 - val_accuracy: 0.7729\n",
            "Epoch 3/25\n",
            "625/625 [==============================] - 890s 1s/step - loss: 0.2988 - accuracy: 0.9101 - val_loss: 0.8003 - val_accuracy: 0.7728\n",
            "Epoch 4/25\n",
            "625/625 [==============================] - 883s 1s/step - loss: 0.2674 - accuracy: 0.9204 - val_loss: 0.7796 - val_accuracy: 0.7835\n",
            "Epoch 5/25\n",
            "625/625 [==============================] - 881s 1s/step - loss: 0.2428 - accuracy: 0.9294 - val_loss: 0.8080 - val_accuracy: 0.7742\n",
            "Epoch 6/25\n",
            "625/625 [==============================] - 899s 1s/step - loss: 0.2230 - accuracy: 0.9353 - val_loss: 0.7852 - val_accuracy: 0.7761\n",
            "Epoch 7/25\n",
            "625/625 [==============================] - 881s 1s/step - loss: 0.2070 - accuracy: 0.9404 - val_loss: 0.7901 - val_accuracy: 0.7774\n",
            "Epoch 8/25\n",
            "625/625 [==============================] - 882s 1s/step - loss: 0.1888 - accuracy: 0.9484 - val_loss: 0.7945 - val_accuracy: 0.7771\n",
            "Epoch 9/25\n",
            "625/625 [==============================] - 884s 1s/step - loss: 0.1753 - accuracy: 0.9516 - val_loss: 0.7874 - val_accuracy: 0.7831\n",
            "Epoch 10/25\n",
            "625/625 [==============================] - 882s 1s/step - loss: 0.1633 - accuracy: 0.9573 - val_loss: 0.7692 - val_accuracy: 0.7866\n",
            "Epoch 11/25\n",
            "625/625 [==============================] - 882s 1s/step - loss: 0.1496 - accuracy: 0.9617 - val_loss: 0.7754 - val_accuracy: 0.7867\n",
            "Epoch 12/25\n",
            "625/625 [==============================] - 883s 1s/step - loss: 0.1396 - accuracy: 0.9651 - val_loss: 0.7848 - val_accuracy: 0.7831\n",
            "Epoch 13/25\n",
            "625/625 [==============================] - 883s 1s/step - loss: 0.1305 - accuracy: 0.9686 - val_loss: 0.7775 - val_accuracy: 0.7875\n",
            "Epoch 14/25\n",
            "625/625 [==============================] - 882s 1s/step - loss: 0.1215 - accuracy: 0.9718 - val_loss: 0.7744 - val_accuracy: 0.7876\n",
            "Epoch 15/25\n",
            "625/625 [==============================] - 884s 1s/step - loss: 0.1137 - accuracy: 0.9746 - val_loss: 0.7929 - val_accuracy: 0.7818\n",
            "Epoch 16/25\n",
            "625/625 [==============================] - 885s 1s/step - loss: 0.1088 - accuracy: 0.9764 - val_loss: 0.7792 - val_accuracy: 0.7882\n",
            "Epoch 17/25\n",
            "625/625 [==============================] - 886s 1s/step - loss: 0.1013 - accuracy: 0.9790 - val_loss: 0.7798 - val_accuracy: 0.7880\n",
            "Epoch 18/25\n",
            "625/625 [==============================] - 884s 1s/step - loss: 0.0951 - accuracy: 0.9809 - val_loss: 0.7905 - val_accuracy: 0.7842\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00018: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNjZtMIbyZ02"
      },
      "source": [
        "model.save_weights(\"./model_nodense_drop_03.h5\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "cV2jvusFF9gs",
        "outputId": "32f41a96-819e-4828-8309-f0cda1c1288f"
      },
      "source": [
        "bs = 18\n",
        "plt.plot(np.arange(0, bs), hist.history['loss'], label='training loss')\n",
        "plt.plot(np.arange(0, bs), hist.history['val_loss'], label='validation loss')\n",
        "plt.plot(np.arange(0, bs), hist.history['accuracy'], label='training accuracy')\n",
        "plt.plot(np.arange(0, bs), hist.history['val_accuracy'], label='validation accuracy')\n",
        "plt.title('Accuracy and Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss|Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whSYBNXKn2un",
        "outputId": "0ad5dba9-8cd7-4d42-a6a3-cd1303b46d4a"
      },
      "source": [
        "model.evaluate(test_gen)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "156/156 [==============================] - 66s 421ms/step - loss: 0.7412 - accuracy: 0.7892\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7412276864051819, 0.7891626358032227]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}