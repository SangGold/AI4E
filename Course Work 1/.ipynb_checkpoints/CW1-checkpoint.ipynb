{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-K6pCg73qJg4"
   },
   "source": [
    "Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kSugLR1BqBrU"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kC7fKSyrqpUO"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "import albumentations as albu\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Flatten, GlobalAveragePooling2D, GlobalMaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VFndlgVdq8BN"
   },
   "outputs": [],
   "source": [
    "(X, y), (X_test, y_test) = cifar100.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GWDbxtlyrGS6",
    "outputId": "a3b762ab-1f87-42f5-97bc-e53ab36a10b6"
   },
   "outputs": [],
   "source": [
    "print(X.shape, y.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YcV3xWebsdpm"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pvM272-6rQ-U",
    "outputId": "3ea67c6e-e458-43a1-a8fb-f2897c796fd9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training data :  40000\n",
      "The number of validation data :  10000\n"
     ]
    }
   ],
   "source": [
    "st = StratifiedShuffleSplit(n_splits = 2, test_size = 0.2, random_state = 1)\n",
    "for train_index, val_index in st.split(X, y):\n",
    "    X_train, X_val, y_train, y_val = X[train_index], X[val_index], y[train_index], y[val_index]        \n",
    "    \n",
    "print(\"The number of training data : \", X_train.shape[0])\n",
    "print(\"The number of validation data : \", X_val.shape[0])\n",
    "del X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "u830tpp1sPUc"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "3uN_gz3e0hBO"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Fs9zFkCZx2iq"
   },
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "def np_resize(img, shape):\n",
    "    return cv2.resize(img, (shape[1], shape[0]), interpolation = cv2.INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "XpPHMZPezA_C"
   },
   "outputs": [],
   "source": [
    "# parameters for data\n",
    "height = 224\n",
    "width = 224\n",
    "channels = 3\n",
    "input_shape = (height, width, channels)\n",
    "n_classes = 100\n",
    "\n",
    "# parameters for optimizers\n",
    "lr = 1e-3\n",
    "\n",
    "# Parameters for training\n",
    "epochs = 25\n",
    "batch_size = 32\n",
    "\n",
    "# parameters for callback functions\n",
    "es_patience = 5\n",
    "rlrop_patience = 5\n",
    "decay_rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "j8Pb2f2nzLlA"
   },
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    'Generates data for keras'\n",
    "    def __init__(self, images , labels = None, mode = 'fit', batch_size = batch_size,\n",
    "                 dim = (height, width), channels = channels, n_classes = n_classes,\n",
    "                 shuffle = True, augment = False):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.mode = mode\n",
    "        self.batch_size = batch_size\n",
    "        self.dim = dim\n",
    "        self.channels = channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(self.images.shape[0])\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            \n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.images) / self.batch_size))\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        batch_indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # =========================================================== #\n",
    "        # Generate mini-batch of X\n",
    "        # =========================================================== #\n",
    "        X = np.empty((self.batch_size, *self.dim, self.channels))\n",
    "        for i, ID in enumerate(batch_indexes):\n",
    "            # Generate a preprocessed image\n",
    "            img = self.images[ID]\n",
    "            img = img.astype(np.float32) / 255.\n",
    "            img = np_resize(img, self.dim)\n",
    "            X[i] = img\n",
    "            \n",
    "        \n",
    "        # =========================================================== #\n",
    "        # Generate mini-batch of y\n",
    "        # =========================================================== #\n",
    "        if self.mode == 'fit':\n",
    "            y = self.labels[batch_indexes]\n",
    "            y = to_categorical(y, n_classes)\n",
    "            '''\n",
    "            y = np.zeros((self.batch_size, self.n_classes), dtype = np.uint8)\n",
    "            for i, ID in enumerate(batch_indexes):\n",
    "                # one hot encoded label\n",
    "                y[i, self.labels[ID]] = 1\n",
    "            '''\n",
    "            # Augmentation should only be implemented in the training part.\n",
    "            if self.augment == True:\n",
    "                X = self.__augment_batch(X)                \n",
    "            \n",
    "            return X,y\n",
    "        \n",
    "        elif self.mode == 'predict':\n",
    "            return X       \n",
    "        \n",
    "        else:\n",
    "            raise AttributeError('The mode parameters should be set to \"fit\" or \"predict\"')\n",
    "            \n",
    "    def __random_transform(self, img):\n",
    "        composition = albu.Compose([albu.HorizontalFlip(p = 0.5),\n",
    "                                    albu.VerticalFlip(p = 0.5),\n",
    "                                    albu.GridDistortion(p = 0.2),\n",
    "                                    albu.ElasticTransform(p = 0.2)])\n",
    "        \n",
    "        return composition(image = img)['image']\n",
    "        \n",
    "    \n",
    "    def __augment_batch(self, img_batch):\n",
    "        for i in range(img_batch.shape[0]):\n",
    "            img_batch[i] = self.__random_transform(img_batch[i])\n",
    "            \n",
    "        return img_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "UWvpEIpDzn-I"
   },
   "outputs": [],
   "source": [
    "train_generator = DataGenerator(X_train, y_train, augment = True)\n",
    "valid_generator = DataGenerator(X_val, y_val, augment = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "H5TjKNBL12-A"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QbAyUEQe0_mb",
    "outputId": "9341826f-0dc0-4566-bfbd-99f84b3cde31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnetb4 (Functional)  (None, 7, 7, 1792)        17673823  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               918016    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               51300     \n",
      "=================================================================\n",
      "Total params: 18,643,139\n",
      "Trainable params: 18,517,932\n",
      "Non-trainable params: 125,207\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pre_train = EfficientNetB4(include_top=False,\n",
    "                           weights='imagenet',\n",
    "                           input_shape=input_shape,\n",
    "                           classes=n_classes)\n",
    "model = Sequential()\n",
    "model.add(pre_train)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "UYiA7YfB3JKD"
   },
   "outputs": [],
   "source": [
    "# warm up\n",
    "pre_train.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Vatl6APC4hwf"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mWgMyoIm3rVj",
    "outputId": "1ca0e2f4-0740-4c54-cbbe-0316d130ec7b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "# callbacks\n",
    "sgd = SGD(lr = lr, momentum = 0.9, nesterov = True)\n",
    "es = EarlyStopping(monitor = 'val_loss', mode = 'min', patience = es_patience, restore_best_weights = True, verbose = 1)\n",
    "rlrop = ReduceLROnPlateau(monitor = 'val_loss', mode = 'min', patience = rlrop_patience, \n",
    "                        factor = decay_rate, min_lr = 1e-6, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "pMzBCGrC4e-z"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pgv-i6SD5LM8",
    "outputId": "0a882426-c3b7-463f-a162-54c0b5521a08"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      " 772/1250 [=================>............] - ETA: 3:51 - loss: 4.6237 - acc: 0.0102"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(train_generator, \n",
    "                           validation_data=valid_generator,\n",
    "                           epochs=epochs,\n",
    "                           verbose=1,\n",
    "                           callbacks=[es, rlrop])\n",
    "\n",
    "model.save_weights('best_weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eZcsM6w76Edb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CW1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
